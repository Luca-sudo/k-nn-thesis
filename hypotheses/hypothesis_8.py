#!/usr/bin/env python3

# Hypothesis 8: LSH-quality and recall are desirable on data distributed on the unit sphere.

import time
import numpy as np
import h5py
import faiss

n_dims = 100
n_sites = [2 ** i for i in range (10, 20)]
k = 5
sample_size = 20
filepath = "data/hypothesis_8.h5"

hypothesis = "LSH-quality and recall are desirable on data distributed on the unit sphere."

description = """
This dataset is generated by uniformly sampling radians $d-1$ times. These angles are then used to calculate the coordinate representation of the associated vector on the unit sphere.
"""

np.random.seed(42)

file = h5py.File(filepath, 'w')
file.attrs['k'] = k
file.attrs['n_instances'] = len(n_sites)
file.attrs['description'] = description
file.attrs['hypothesis'] = hypothesis
file.attrs['sample_size'] = sample_size
file.attrs['var_name'] = "Nr. of Sites"
file.attrs['var_values'] = n_sites

# Turn d-1 angles into a d-dimensional coordinate vector.
def rad_to_coordinate(angles):
    coordinates = []
    # Precompute sines and cosines
    sines = np.sin(angles)
    cosines = np.cos(angles)
    for i in range(len(angles) + 1):
        x = 1
        for j in range(i):
            x *= sines[j]
        if i < len(angles):
            x *= cosines[i]
        coordinates.append(x)
    return coordinates


for i in range(len(n_sites)):
    print(f'Generating instance {i}:')
    time_start = time.perf_counter()
    # d - 1 many angles required for the d-dimensional representation
    angles = np.random.uniform(0, 2.0 * np.pi, (n_sites[i], n_dims - 1))
    sites = list(map(rad_to_coordinate, angles))
    sites = np.array(sites, dtype=np.float32)
    time_end = time.perf_counter()
    print(f'\tGenerating sites: {time_end - time_start:.3f} seconds')
    query_angles = np.random.uniform(0, 2.0 * np.pi, (sample_size, n_dims - 1))
    queries = np.array(list(map(rad_to_coordinate, query_angles)), dtype=np.float32)
    print(f'queries: {queries}')
    time_start = time.perf_counter()
    index = faiss.IndexFlatL2(n_dims)
    index.add(sites)
    time_end = time.perf_counter()
    print(f'\tGenerating flat index: {time_end - time_start:.3f} seconds')

    time_start = time.perf_counter()
    distance, solution = index.search(queries, n_sites[i])
    time_end = time.perf_counter()
    print(f'\tComputing solution: {time_end - time_start:.3f} seconds')

    k_nearest = list(map(lambda x: x[:k], solution))
    ranks = solution
    k_nearest_distances = list(map(lambda x: x[:k], distance))

    def invert(l):
        new_l = [0 for i in range(len(l))]

        for index, value in enumerate(l):
            new_l[value] = index + 1

        return new_l

    ranks = list(map(invert, ranks))

    instance = file.create_dataset('instance_' + str(i), data=sites)
    instance.attrs['n_sites'] = n_sites
    instance.attrs['n_dims'] = n_dims
    instance.attrs['n_planes'] = n_dims * 2
    file.create_dataset('queries_' + str(i), data=queries)
    file.create_dataset('solution_' + str(i), data=k_nearest)
    file.create_dataset('ranks_' + str(i), data = ranks)
    file.create_dataset('distance_' + str(i), data=k_nearest_distances)
